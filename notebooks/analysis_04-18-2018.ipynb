{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rahul Kumar Goyal (rxg170030) & Varun Kumar Manohara Selvan (vxm170030)\n",
    "### Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cardiac Arrhythmia Multi-Class Classification \n",
    "\n",
    "Analyze data and address missing data if there is any. \n",
    "\n",
    "Decide aboute a good evaluation strategy and justify your choice. \n",
    "\n",
    "Find the best parameters for the following classification models: \n",
    "- KNN classifcation \n",
    "- Logistic Regression\n",
    "- Linear Supprt Vector Machine\n",
    "- Kerenilzed Support Vector Machine\n",
    "- Decision Tree\n",
    "- Random Forest \n",
    "\n",
    "Then use different bagging and boosting methods to boost the results? Do you see any significant change? Why or why not? \n",
    "\n",
    "Next, use data reduction method you have learned in class to reduce the size of data, and agian try above models. Do you get better results? Justify your answer. \n",
    "\n",
    "<font color = 'red'>Due date for full credit: April 4, 11:59 PM\n",
    "    <br>\n",
    "    Due date for partial credit: April 6, 11:59 PM.\n",
    "    <br> No submission will be accepted after April 6. \n",
    "    <br> Please note that your term paper is also due April 6. \n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the required libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedKFold\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn import linear_model, decomposition\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Dataset. There are no column names in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cardiac_arrhythmia.csv', header=None, na_values=['?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names were made into a list by taking information from the metadata document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colnames = [\"Age\", \"Gender\", \"Height\", \"Weight\", \"QRS_Duration\", \"PR_Interval\",\n",
    "           \"QT_Interval\",\"T_Interval\",\"P_Interval\"]\n",
    "for name in [\"QRS\",\"T\",\"P\",\"QRST\",\"J\"]:\n",
    "    colnames.append(\"VectorAngle_\"+name)\n",
    "\n",
    "colnames.append(\"HeartRate\")\n",
    "\n",
    "channels = [\"DI\",\"DII\",\"DIII\",\"AVR\",\"AVL\",\"AVF\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\"]\n",
    "channel_specs_1 = [\"QWidth\",\"RWidth\",\"SWidth\",\"RPWidth\",\"SPWidth\",\"NumDeflections\",\n",
    "                 \"ExistRagR\",\"ExistDiaR\",\"ExistRagP\",\"ExistDiaP\",\"ExistRagT\",\"ExistDiaT\"]\n",
    "channel_specs_2 = [\"AmpJJ\",\"AmpQ\",\"AmpR\",\"AmpS\",\"AmpRP\",\n",
    "                 \"AmpSP\",\"AmpP\",\"AmpT\",\"QRSA\",\"QRSTA\"]\n",
    "\n",
    "for channel in channels:\n",
    "    for spec in channel_specs_1:\n",
    "        colnames.append(channel+\"_\"+spec)\n",
    "\n",
    "for channel in channels:\n",
    "    for spec in channel_specs_2:\n",
    "        colnames.append(channel+\"_\"+spec)\n",
    "\n",
    "colnames.append(\"Target\")\n",
    "\n",
    "#Seperate Nominal and Linear columns for future\n",
    "channel_spec = [\"ExistRagR\",\"ExistDiaR\",\"ExistRagP\",\"ExistDiaP\",\"ExistRagT\",\"ExistDiaT\"]\n",
    "channels = [\"DI\",\"DII\",\"DIII\",\"AVR\",\"AVL\",\"AVF\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\"]\n",
    "\n",
    "NominalCols = [\"Gender\"]\n",
    "\n",
    "for channel in channels:\n",
    "    for spec in channel_spec:\n",
    "        NominalCols.append(channel+\"_\"+spec)\n",
    "\n",
    "LinearCols = [i for i in colnames if i not in NominalCols]\n",
    "\n",
    "LinearCols = LinearCols[:-1] #Remove the \"Target\" column from LinearCols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the column names in df to the colnames list created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>QRS_Duration</th>\n",
       "      <th>PR_Interval</th>\n",
       "      <th>QT_Interval</th>\n",
       "      <th>T_Interval</th>\n",
       "      <th>P_Interval</th>\n",
       "      <th>VectorAngle_QRS</th>\n",
       "      <th>...</th>\n",
       "      <th>V6_AmpQ</th>\n",
       "      <th>V6_AmpR</th>\n",
       "      <th>V6_AmpS</th>\n",
       "      <th>V6_AmpRP</th>\n",
       "      <th>V6_AmpSP</th>\n",
       "      <th>V6_AmpP</th>\n",
       "      <th>V6_AmpT</th>\n",
       "      <th>V6_QRSA</th>\n",
       "      <th>V6_QRSTA</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Height  Weight  QRS_Duration  PR_Interval  QT_Interval  \\\n",
       "0   75       0     190      80            91          193          371   \n",
       "1   56       1     165      64            81          174          401   \n",
       "2   54       0     172      95           138          163          386   \n",
       "3   55       0     175      94           100          202          380   \n",
       "4   75       0     190      80            88          181          360   \n",
       "\n",
       "   T_Interval  P_Interval  VectorAngle_QRS   ...    V6_AmpQ  V6_AmpR  V6_AmpS  \\\n",
       "0         174         121              -16   ...        0.0      9.0     -0.9   \n",
       "1         149          39               25   ...        0.0      8.5      0.0   \n",
       "2         185         102               96   ...        0.0      9.5     -2.4   \n",
       "3         179         143               28   ...        0.0     12.2     -2.2   \n",
       "4         177         103              -16   ...        0.0     13.1     -3.6   \n",
       "\n",
       "   V6_AmpRP  V6_AmpSP  V6_AmpP  V6_AmpT  V6_QRSA  V6_QRSTA  Target  \n",
       "0       0.0         0      0.9      2.9     23.3      49.4       8  \n",
       "1       0.0         0      0.2      2.1     20.4      38.8       6  \n",
       "2       0.0         0      0.3      3.4     12.3      49.0      10  \n",
       "3       0.0         0      0.4      2.6     34.6      61.6       1  \n",
       "4       0.0         0     -0.1      3.9     25.4      62.8       7  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   8  22   1 376   1   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "(452, 280)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(df.isnull().sum()))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, missing values are filled using average for linear columns. For nominal columns there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Check to see if the nominal columns have more than 2 values. If there are we might want to convert them to one_hot.<br>\n",
    "2) Print the columns which have only one value as they will be of no use in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nominal Columns\n",
      "Unique values in AVL_ExistRagR column are: [0]\n",
      "Unique values in AVF_ExistRagP column are: [0]\n",
      "Unique values in V4_ExistRagP column are: [0]\n",
      "Unique values in V4_ExistDiaP column are: [0]\n",
      "Unique values in V5_ExistRagR column are: [0]\n",
      "Unique values in V5_ExistRagP column are: [0]\n",
      "Unique values in V5_ExistRagT column are: [0]\n",
      "Unique values in V6_ExistDiaP column are: [0]\n",
      "Unique values in V6_ExistRagT column are: [0]\n",
      "\n",
      "\n",
      "Linear Columns\n",
      "Unique values in DI_SPWidth column are: [0]\n",
      "Unique values in AVL_SPWidth column are: [0]\n",
      "Unique values in V5_SPWidth column are: [0]\n",
      "Unique values in V6_SPWidth column are: [0]\n",
      "Unique values in DI_AmpSP column are: [0]\n",
      "Unique values in AVL_AmpSP column are: [0]\n",
      "Unique values in V5_AmpSP column are: [0]\n",
      "Unique values in V6_AmpSP column are: [0]\n"
     ]
    }
   ],
   "source": [
    "#Check number of unique values in nominal columns to see if it is required to convert any to one_hot\n",
    "#Next check linear columns which only have one unique values\n",
    "\n",
    "print('Nominal Columns')\n",
    "for col in NominalCols:\n",
    "    if len(df[col].unique()) != 2:\n",
    "        print(\"Unique values in \"+col+\" column are: \",end=\"\")\n",
    "        print(df[col].unique())\n",
    "        \n",
    "print('\\n')\n",
    "print('Linear Columns')\n",
    "for col in LinearCols:\n",
    "    if len(df[col].unique()) == 1:\n",
    "        print(\"Unique values in \"+col+\" column are: \",end=\"\")\n",
    "        print(df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) No nominal columns have more than 2 values. So we don't have to convert any column to one hot. <br>\n",
    "2) Few nominal and linear columns have only one value so remove them and update the NominalCols and LinearCols list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if len(df[col].unique()) == 1:\n",
    "        df.drop(col, inplace=True, axis=1)\n",
    "\n",
    "#Update the nominal and linear columns list\n",
    "NominalCols = [i for i in NominalCols if i in df.columns]\n",
    "LinearCols = [i for i in LinearCols if i in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models built will be<br>\n",
    "1) Logistic Regression (Multinomial and OneVersusRest)<br>\n",
    "2) Support Vector Classifier (linear and rbf kernels)<br>\n",
    "3) Decision Tree Classifier<br>\n",
    "4) Random Forests<br>\n",
    "5) K Nearest Neighbors<br>\n",
    "6) Gradient Boosting Classifier<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the features and target in the dataset and do min max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[df.columns[:-1]]\n",
    "y = df['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1, stratify = y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few helper functions are used for the analysis.<br>\n",
    "1) **multiclass_roc_auc_score**: Scikit learn's roc and auc functions do the work only for binary classfication problem, this function calculates the AUC for the multiclass classification problem we have<br>\n",
    "2) **var_imp_plot**: This function plots the important variables for the different models that we plot <br>\n",
    "3) **print_grid_search**: This function plots few metrics from grid search of use to us<br>\n",
    "4) **print_model_scores**: This functions prints a few results we want from a model like classification report etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(truth, pred, average=\"macro\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)\n",
    "    pred = lb.transform(pred)\n",
    "\n",
    "    return(roc_auc_score(truth, pred, average=average))\n",
    "\n",
    "def var_imp_plot(model, df = df):\n",
    "    \n",
    "    feature_importance = model.feature_importances_\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    \n",
    "    column_names = df.columns[:-1]\n",
    "\n",
    "    imp = list(zip(column_names, feature_importance))\n",
    "    x = sorted(imp, reverse=True, key= lambda x: x[1])[0:20][::-1]\n",
    "\n",
    "    sorted_idx = np.argsort(feature_importance)[0:20]\n",
    "    pos = np.arange(sorted_idx.shape[0])+0.5\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(pos, [a[1] for a in x], align='center')\n",
    "    plt.yticks(pos, [a[0] for a in x])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title('Variable Importance')\n",
    "    plt.show()\n",
    "    \n",
    "def print_grid_search(grid_search):\n",
    "    \n",
    "    print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "    print( \"Best estimator:\\n{}\".format(grid_search.best_estimator_))\n",
    "    \n",
    "def print_model_scores(model, y_test = y_test, X_test_scaled = X_test_scaled, X_train_scaled = X_train_scaled, y_train = y_train):\n",
    "    \n",
    "    y_predicted = model.predict(X_test_scaled)\n",
    "    \n",
    "    print(\"training score : %.4f \" % (model.score(X_train_scaled, y_train)))\n",
    "    print(\"testing score : %.4f \" % (model.score(X_test_scaled, y_test)))\n",
    "    \n",
    "    print(\"Testing report :\")\n",
    "    print(classification_report(y_test, y_predicted))\n",
    "    \n",
    "    print(\"Confusion matrix: \")\n",
    "    print(confusion_matrix(y_test, y_predicted))\n",
    "    \n",
    "    print(\"AUC: {:.4f}\".format(multiclass_roc_auc_score(y_test, y_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The model building process for each model will be as follows:\n",
    "###### 1) Do Grid Search on each model to find the best estimator \n",
    "###### 2) Use the best estimator to build that specific model\n",
    "###### 3) Bagging and Boosting (if applicable) the best estimator to try and get better results \n",
    "###### 4) Decide the best model based on the maximum accuracy and maximum roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search to find the best value for C in both the Multionomial and One Versus Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinomial\n",
      "Best parameters: {'C': 1}\n",
      "Best cross-validation score: 0.68\n",
      "Best estimator:\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
      "          n_jobs=1, penalty='l2', random_state=1, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "ovr\n",
      "Best parameters: {'C': 0.5}\n",
      "Best cross-validation score: 0.68\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=1, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C':[0.1,0.5,1,2,5,10]}\n",
    "\n",
    "for multi_class in ('multinomial', 'ovr'):\n",
    "    grid_search = GridSearchCV(linear_model.LogisticRegression(solver='sag', random_state=1, multi_class=multi_class),\n",
    "                               param_grid, cv=StratifiedKFold(5, shuffle = True, random_state = 1))\n",
    "\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(multi_class)\n",
    "    print_grid_search(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the multiclass logistic regression model for multinomial and one versus rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinomial\n",
      "training score : 0.8344 \n",
      "testing score : 0.7200 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.99      0.82        81\n",
      "          2       0.75      0.40      0.52        15\n",
      "          3       1.00      1.00      1.00         5\n",
      "          4       0.50      0.40      0.44         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.81      0.76      0.79        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.61      0.72      0.65       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[80  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  6  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  2  0  0  0  0  0  1  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0 13  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "AUC: 0.6408\n",
      "ovr\n",
      "training score : 0.7682 \n",
      "testing score : 0.6800 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.99      0.80        81\n",
      "          2       0.67      0.40      0.50        15\n",
      "          3       1.00      1.00      1.00         5\n",
      "          4       0.33      0.20      0.25         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.33      0.50         3\n",
      "         10       0.75      0.53      0.62        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.58      0.68      0.60       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[80  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  6  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  1  0  1  0  0  0  0  0  1  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 8  0  0  0  0  0  0  0  0  9  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "AUC: 0.6082\n"
     ]
    }
   ],
   "source": [
    "for multi_class, c in [('multinomial',1), ('ovr', 0.5)]:\n",
    "    clf = linear_model.LogisticRegression(solver='sag', random_state=1, C = c,\n",
    "                             multi_class=multi_class).fit(X_train_scaled, y_train)\n",
    "\n",
    "    # print the training scores\n",
    "    print(multi_class)\n",
    "    print_model_scores(model = clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting and Bagging both the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging\n",
      "multinomial\n",
      "training score : 0.8013 \n",
      "testing score : 0.7067 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.99      0.81        81\n",
      "          2       0.60      0.40      0.48        15\n",
      "          3       1.00      1.00      1.00         5\n",
      "          4       0.60      0.60      0.60         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.33      0.50         3\n",
      "         10       0.85      0.65      0.73        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.60      0.71      0.63       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[80  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  6  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  3  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 5  1  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "AUC: 0.6303\n",
      "ovr\n",
      "training score : 0.7517 \n",
      "testing score : 0.6800 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.99      0.78        81\n",
      "          2       0.75      0.40      0.52        15\n",
      "          3       1.00      1.00      1.00         5\n",
      "          4       0.50      0.20      0.29         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.33      0.50         3\n",
      "         10       0.82      0.53      0.64        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.59      0.68      0.60       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[80  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  6  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  1  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 8  0  0  0  0  0  0  0  0  9  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "AUC: 0.6073\n",
      "AdaBoost\n",
      "multinomial\n",
      "training score : 0.6589 \n",
      "testing score : 0.6067 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.99      0.74        81\n",
      "          2       0.50      0.13      0.21        15\n",
      "          3       1.00      0.40      0.57         5\n",
      "          4       0.00      0.00      0.00         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.33      0.50         3\n",
      "         10       1.00      0.35      0.52        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.53      0.61      0.51       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[80  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [13  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [11  0  0  0  0  0  0  0  0  6  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "AUC: 0.5528\n",
      "ovr\n",
      "training score : 0.5828 \n",
      "testing score : 0.5667 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      1.00      0.71        81\n",
      "          2       0.00      0.00      0.00        15\n",
      "          3       0.00      0.00      0.00         5\n",
      "          4       0.00      0.00      0.00         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.33      0.50         3\n",
      "         10       1.00      0.18      0.30        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.43      0.57      0.43       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[81  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [14  0  0  0  0  0  0  0  0  3  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "AUC: 0.5218\n"
     ]
    }
   ],
   "source": [
    "print(\"Bagging\")\n",
    "for multi_class, c in [('multinomial',1), ('ovr', 0.5)]:\n",
    "    clf = BaggingClassifier(linear_model.LogisticRegression(solver='sag', random_state=1, C = c,\n",
    "                             multi_class=multi_class)).fit(X_train_scaled, y_train)\n",
    "\n",
    "    # print the training scores\n",
    "    print(multi_class)\n",
    "    print_model_scores(model = clf)\n",
    "    \n",
    "print(\"AdaBoost\")\n",
    "for multi_class, c in [('multinomial',1), ('ovr', 0.5)]:\n",
    "    clf = AdaBoostClassifier(linear_model.LogisticRegression(solver='sag', random_state=1, C = c,\n",
    "                             multi_class=multi_class)).fit(X_train_scaled, y_train)\n",
    "\n",
    "    # print the training scores\n",
    "    print(multi_class)\n",
    "    print_model_scores(model = clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search on Support Vector Classifier to find best values for C using a linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1}\n",
      "Best cross-validation score: 0.68\n",
      "Best estimator:\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(kernel = 'linear', random_state = 1),\n",
    "                           param_grid, cv=StratifiedKFold(5, shuffle = True, random_state = 1))\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print_grid_search(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build linear SVC using the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 0.9238 \n",
      "testing score : 0.7200 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.96      0.82        81\n",
      "          2       0.88      0.47      0.61        15\n",
      "          3       1.00      1.00      1.00         5\n",
      "          4       0.50      0.80      0.62         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.83      0.59      0.69        17\n",
      "         14       0.50      1.00      0.67         1\n",
      "         15       1.00      0.50      0.67         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.65      0.72      0.66       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[78  1  0  1  0  0  0  0  0  1  0  0  0]\n",
      " [ 8  7  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  4  0  0  0  1  0  0  0  0  0]\n",
      " [ 3  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 4  0  0  1  0  0  1  0  0 10  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 6  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "AUC: 0.7096\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=1, kernel='linear', random_state=1).fit(X_train_scaled, y_train)\n",
    "\n",
    "print_model_scores(model = svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging and boosting linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 0.7450 \n",
      "testing score : 0.6333 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.99      0.80        81\n",
      "          2       0.86      0.40      0.55        15\n",
      "          3       1.00      1.00      1.00         5\n",
      "          4       0.57      0.80      0.67         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         3\n",
      "         10       0.00      0.00      0.00        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.50      0.63      0.54       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[80  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  6  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  4  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  0  2  0  7  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "AUC: 0.5969\n"
     ]
    }
   ],
   "source": [
    "svc = BaggingClassifier(SVC(C=1, kernel='linear', random_state=1)).fit(X_train_scaled, y_train)\n",
    "\n",
    "print_model_scores(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search on Support Vector Classifier to find best values for C and gamma using a rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'gamma': 0.05}\n",
      "Best cross-validation score: 0.70\n",
      "Best estimator:\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.05, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 10, 100, 200, 400, 500],\n",
    "              'gamma': [0.001, 0.01, 0.05, 0.1]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(kernel = 'rbf', random_state = 1),\n",
    "                           param_grid, cv=StratifiedKFold(5, shuffle = True, random_state = 1))\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print_grid_search(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build radial kernel SVM using the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 0.9305 \n",
      "testing score : 0.7067 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.95      0.81        81\n",
      "          2       0.78      0.47      0.58        15\n",
      "          3       1.00      1.00      1.00         5\n",
      "          4       0.67      0.80      0.73         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       1.00      0.12      0.22         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.75      0.53      0.62        17\n",
      "         14       1.00      1.00      1.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.68      0.71      0.66       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[77  0  0  1  0  0  0  0  0  1  0  0  2]\n",
      " [ 7  7  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  4  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  0  1  0  1  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 5  1  0  0  0  0  0  0  0  9  0  0  2]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "AUC: 0.6916\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=10, gamma=0.05, kernel='rbf', random_state=1).fit(X_train_scaled, y_train)\n",
    "\n",
    "print_model_scores(model = svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging and boosting SVC with rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 0.8278 \n",
      "testing score : 0.6667 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.98      0.79        81\n",
      "          2       0.55      0.40      0.46        15\n",
      "          3       0.83      1.00      0.91         5\n",
      "          4       1.00      0.80      0.89         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.67      0.67      0.67         3\n",
      "         10       1.00      0.24      0.38        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.60      0.67      0.59       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[79  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 9  6  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  4  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 8  2  0  0  0  0  1  0  1  4  0  1  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "AUC: 0.6315\n"
     ]
    }
   ],
   "source": [
    "svc = BaggingClassifier(SVC(C=10, gamma=0.05, kernel='rbf', random_state=1)).fit(X_train_scaled, y_train)\n",
    "\n",
    "print_model_scores(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search on Decision Tree to find best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 8}\n",
      "Best cross-validation score: 0.66\n",
      "Best estimator:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': np.arange(3, 10)}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=1),\n",
    "                           param_grid, cv=StratifiedKFold(5, shuffle = True, random_state = 1))\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print_grid_search(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Decision Tree using best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 0.9205 \n",
      "testing score : 0.6600 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.90      0.78        81\n",
      "          2       0.50      0.27      0.35        15\n",
      "          3       0.80      0.80      0.80         5\n",
      "          4       0.50      0.40      0.44         5\n",
      "          5       1.00      0.50      0.67         4\n",
      "          6       1.00      0.38      0.55         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.33      0.50         3\n",
      "         10       0.45      0.53      0.49        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       1.00      0.14      0.25         7\n",
      "\n",
      "avg / total       0.66      0.66      0.62       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[73  1  0  0  0  0  0  0  0  7  0  0  0]\n",
      " [ 7  4  0  2  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  1  4  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  2  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  1  0  0  3  0  0  0  1  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 8  0  0  0  0  0  0  0  0  9  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 5  1  0  0  0  0  0  0  0  0  0  0  1]]\n",
      "AUC: 0.6399\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 8, random_state=1).fit(X_train_scaled, y_train)\n",
    "\n",
    "print_model_scores(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging and boosting decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging\n",
      "training score : 0.9470 \n",
      "testing score : 0.7200 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.94      0.81        81\n",
      "          2       0.73      0.53      0.62        15\n",
      "          3       0.80      0.80      0.80         5\n",
      "          4       1.00      0.40      0.57         5\n",
      "          5       0.67      0.50      0.57         4\n",
      "          6       1.00      0.62      0.77         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.56      0.53      0.55        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.67      0.72      0.68       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[76  1  0  0  0  0  0  0  0  4  0  0  0]\n",
      " [ 6  8  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 1  0  4  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  2  1  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  2  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  1  0  0  5  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  1  0  0  0]\n",
      " [ 8  0  0  0  0  0  0  0  0  9  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  1  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "AUC: 0.6719\n",
      "Boosting\n",
      "training score : 1.0000 \n",
      "testing score : 0.6733 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.98      0.77        81\n",
      "          2       0.67      0.27      0.38        15\n",
      "          3       0.83      1.00      0.91         5\n",
      "          4       1.00      0.40      0.57         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       1.00      0.38      0.55         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.86      0.35      0.50        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.64      0.67      0.61       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[79  1  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [11  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  1  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [11  0  0  0  0  0  0  0  0  6  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "AUC: 0.6290\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAAEWCAYAAABFZHMLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQVATIpgEQVAT/j9sDAFVGBhgnAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ca2637aba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt = BaggingClassifier(DecisionTreeClassifier(max_depth = 8, random_state=1)).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Bagging\")\n",
    "print_model_scores(dt)\n",
    "\n",
    "dt = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 8, random_state=1)).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Boosting\")\n",
    "print_model_scores(dt)\n",
    "var_imp_plot(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search on RandomForest to find best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 700}\n",
      "Best cross-validation score: 0.69\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=700, n_jobs=1,\n",
      "            oob_score=False, random_state=1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\": [200, 500, 700]}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=1), param_grid,\n",
    "                           cv=StratifiedKFold(5, shuffle = True, random_state = 1))\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print_grid_search(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model using random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 1.0000 \n",
      "testing score : 0.7400 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.98      0.82        81\n",
      "          2       0.73      0.53      0.62        15\n",
      "          3       0.83      1.00      0.91         5\n",
      "          4       1.00      0.80      0.89         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       1.00      0.25      0.40         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.85      0.65      0.73        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.68      0.74      0.68       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[79  1  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 7  8  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  4  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  0  1  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 6  0  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  1  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "AUC: 0.6673\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAAEWCAYAAABFZHMLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ca2a4f8048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=1,\n",
    "                                n_estimators = 700).fit(X_train_scaled, y_train)\n",
    "\n",
    "print_model_scores(rf_clf)\n",
    "\n",
    "var_imp_plot(rf_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Grid Search or CV for Gradientboosting to find best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 5}\n",
      "Best cross-validation score: 0.71\n",
      "Best estimator:\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.01, loss='deviance', max_depth=5,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "             'max_depth':[3, 5, 9]}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(random_state = 1),\n",
    "                           param_grid, cv=StratifiedKFold(5, shuffle = True, random_state = 1))\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model using the best model in GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 0.9901 \n",
      "testing score : 0.7200 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.94      0.83        81\n",
      "          2       0.75      0.60      0.67        15\n",
      "          3       0.83      1.00      0.91         5\n",
      "          4       0.67      0.40      0.50         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       1.00      0.50      0.67         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.67      0.67      0.67         3\n",
      "         10       0.69      0.53      0.60        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.50      0.50      0.50         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.68      0.72      0.69       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[76  1  0  0  0  0  0  0  0  1  1  0  2]\n",
      " [ 3  9  0  0  0  0  0  0  1  2  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  4  0  0  0  0  0  1  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  2  0  0  0  0]\n",
      " [ 6  0  0  1  1  0  0  0  0  9  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 3  2  1  0  0  0  0  0  0  1  0  0  0]]\n",
      "AUC: 0.6786\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAEWCAYAAABVIWr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6YNkxU6SPkhW7CTpg/x/KRmBD5E9uwoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ca292b6eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(learning_rate = 0.01,max_depth = 5,random_state = 1).fit(X_train_scaled, y_train)\n",
    "\n",
    "print_model_scores(gb_clf)\n",
    "\n",
    "var_imp_plot(gb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging and boosting XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 0.9735 \n",
      "testing score : 0.7667 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.99      0.86        81\n",
      "          2       0.91      0.67      0.77        15\n",
      "          3       0.83      1.00      0.91         5\n",
      "          4       0.75      0.60      0.67         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       1.00      0.75      0.86         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.69      0.53      0.60        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.70      0.77      0.72       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[80  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 4 10  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  3  0  0  0  0  0  1  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  1  0  0  6  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 6  0  0  1  1  0  0  0  0  9  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 5  1  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "AUC: 0.6830\n",
      "training score : 1.0000 \n",
      "testing score : 0.7400 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.99      0.85        81\n",
      "          2       0.82      0.60      0.69        15\n",
      "          3       1.00      1.00      1.00         5\n",
      "          4       0.75      0.60      0.67         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       1.00      0.50      0.67         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.67      0.67      0.67         3\n",
      "         10       0.70      0.41      0.52        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       1.00      0.50      0.67         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.70      0.74      0.70       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[80  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  9  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  3  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  4  0  0  0  1  1  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  2  0  0  0  0]\n",
      " [ 7  0  0  1  1  0  1  0  0  7  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 4  1  0  0  0  0  0  0  1  1  0  0  0]]\n",
      "AUC: 0.6839\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO8AAAEWCAYAAACOmsDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ca29482400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb_clf = BaggingClassifier(GradientBoostingClassifier(learning_rate = 0.01,\n",
    "                                                      max_depth = 5,random_state = 1)).fit(X_train_scaled, y_train)\n",
    "\n",
    "print_model_scores(gb_clf)\n",
    "\n",
    "gb_clf = AdaBoostClassifier(GradientBoostingClassifier(learning_rate = 0.01,\n",
    "                                                       max_depth = 5,random_state = 1)).fit(X_train_scaled, y_train)\n",
    "\n",
    "print_model_scores(gb_clf)\n",
    "var_imp_plot(gb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using Grid Search for finding best KNN estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_neighbors': 5}\n",
      "Best cross-validation score: 0.58\n",
      "Best estimator:\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "CV results: {'mean_fit_time': array([ 0.00571828,  0.00249581,  0.00191245,  0.00210528,  0.00290685]), 'std_fit_time': array([ 0.00154108,  0.00054824,  0.0002047 ,  0.00049089,  0.00097192]), 'mean_score_time': array([ 0.02195749,  0.00822883,  0.00802794,  0.00802169,  0.01243372]), 'std_score_time': array([ 0.00518933,  0.00111887,  0.00089434,  0.00031711,  0.00374385]), 'param_n_neighbors': masked_array(data = [1 2 4 5 10],\n",
      "             mask = [False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'n_neighbors': 1}, {'n_neighbors': 2}, {'n_neighbors': 4}, {'n_neighbors': 5}, {'n_neighbors': 10}], 'split0_test_score': array([ 0.57142857,  0.55555556,  0.50793651,  0.55555556,  0.53968254]), 'split1_test_score': array([ 0.46031746,  0.55555556,  0.53968254,  0.53968254,  0.52380952]), 'split2_test_score': array([ 0.54237288,  0.57627119,  0.55932203,  0.57627119,  0.55932203]), 'split3_test_score': array([ 0.64516129,  0.59677419,  0.61290323,  0.59677419,  0.59677419]), 'split4_test_score': array([ 0.58181818,  0.56363636,  0.63636364,  0.63636364,  0.63636364]), 'mean_test_score': array([ 0.55960265,  0.56953642,  0.56953642,  0.5794702 ,  0.56953642]), 'std_test_score': array([ 0.06112502,  0.0157817 ,  0.04687544,  0.0332041 ,  0.0401015 ]), 'rank_test_score': array([5, 2, 2, 1, 2]), 'split0_train_score': array([ 1.        ,  0.69874477,  0.65271967,  0.66108787,  0.58995816]), 'split1_train_score': array([ 1.        ,  0.71129707,  0.67364017,  0.67782427,  0.59832636]), 'split2_train_score': array([ 1.        ,  0.69958848,  0.64197531,  0.65020576,  0.58847737]), 'split3_train_score': array([ 1.        ,  0.67083333,  0.62083333,  0.60416667,  0.5625    ]), 'split4_train_score': array([ 1.        ,  0.70445344,  0.63157895,  0.63562753,  0.56680162]), 'mean_train_score': array([ 1.        ,  0.69698342,  0.64414948,  0.64578242,  0.5812127 ]), 'std_train_score': array([ 0.        ,  0.01381592,  0.01816335,  0.02496195,  0.01399986])}\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors':[1, 2, 4, 5, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(knn_clf , param_grid, cv = StratifiedKFold(5, shuffle = True, random_state = 1),\n",
    "                               scoring = new_score,return_train_score=True)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print_grid_search(grid_search)\n",
    "print(\"CV results: \", end=\"\")\n",
    "print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model using the best model in KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 0.6523 \n",
      "testing score : 0.5933 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.95      0.72        81\n",
      "          2       0.33      0.07      0.11        15\n",
      "          3       1.00      0.80      0.89         5\n",
      "          4       1.00      0.40      0.57         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.33      0.50         3\n",
      "         10       1.00      0.24      0.38        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.55      0.59      0.50       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[77  1  0  0  0  3  0  0  0  0  0  0  0]\n",
      " [14  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  4  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [13  0  0  0  0  0  0  0  0  4  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "AUC: 0.5748\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors = 5).fit(X_train_scaled, y_train)\n",
    "\n",
    "print_model_scores(model=knn_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 0.6589 \n",
      "testing score : 0.5800 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.93      0.72        81\n",
      "          2       0.25      0.07      0.11        15\n",
      "          3       1.00      0.80      0.89         5\n",
      "          4       1.00      0.20      0.33         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.33      0.50         3\n",
      "         10       1.00      0.29      0.45        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.54      0.58      0.50       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[75  2  0  0  0  4  0  0  0  0  0  0  0]\n",
      " [14  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  4  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  1  0  0  0  1  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [11  0  0  0  0  1  0  0  0  5  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "AUC: 0.5685\n"
     ]
    }
   ],
   "source": [
    "knn_clf = BaggingClassifier(KNeighborsClassifier(n_neighbors = 5)).fit(X_train_scaled, y_train)\n",
    "\n",
    "print_model_scores(model=knn_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see most of the models here are overfitting the training data. This is also a multiclass classification problem so we have taken AUC as the measure to select few best models. We can reduce a little complexity on those data to give a goodfit instead of the overfit which we have now. The best models considering AUC as the scoring criteria are as follows:<br>\n",
    "1) **SVC with linear and rbf kernels** (AUC ~ 71 and 68)<br>\n",
    "2) **GradientBoosting with Bagging and Boosting** (AUC ~ 70 and 69)<br>\n",
    "3) **Decision tree with Bagging** (AUC ~ 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance lost is: 2.17418271421625%\n",
      "Sum of explained variance is: 99.999950772%\n"
     ]
    }
   ],
   "source": [
    "pca = decomposition.PCA(n_components=220)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "X_pca_inv = pca.inverse_transform(X_pca)\n",
    "\n",
    "print(\"Variance lost is: \",end=\"\")\n",
    "print(np.mean(np.sum(np.square(X_pca_inv - X), axis=1))*100, end=\"\")\n",
    "print(\"%\")\n",
    "\n",
    "print(\"Sum of explained variance is: \", end=\"\")\n",
    "print(np.sum(pca.explained_variance_ratio_)*100,end=\"\")\n",
    "print(\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the train and test set after pca for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.33, random_state=1, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Seeach on SVC linear kernel to find best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1}\n",
      "Best cross-validation score: 0.68\n",
      "Best estimator:\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 200, 500]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(kernel = 'linear', random_state = 1),\n",
    "                           param_grid, cv=StratifiedKFold(5, shuffle = True, random_state = 1))\n",
    "\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "print_grid_search(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building SVC using best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 1.0000 \n",
      "testing score : 0.6133 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.80      0.76        81\n",
      "          2       0.40      0.27      0.32        15\n",
      "          3       1.00      1.00      1.00         5\n",
      "          4       0.38      0.60      0.46         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.44      0.50      0.47         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      1.00      1.00         3\n",
      "         10       0.58      0.41      0.48        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       1.00      0.50      0.67         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.60      0.61      0.60       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[65  2  0  2  2  3  0  0  0  2  0  0  5]\n",
      " [ 7  4  0  0  0  1  0  0  0  1  0  0  2]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  3  0  0  0  1  0  0  0  0  0]\n",
      " [ 1  2  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  1  0  4  0  0  0  1  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0]\n",
      " [ 7  0  0  1  0  1  0  0  0  7  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 6  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "AUC: 0.6725\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=0.1, kernel='linear', random_state=1).fit(X_train_pca, y_train)\n",
    "\n",
    "print_model_scores(model = svc, X_test_scaled=X_test_pca, X_train_scaled = X_train_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search on SVC with rbf kernel to find best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'gamma': 0.0001}\n",
      "Best cross-validation score: 0.55\n",
      "Best estimator:\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 10, 100, 200, 400, 500],\n",
    "              'gamma': [0.0001, 0.005, 0.001, 0.01]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(kernel = 'rbf', random_state = 1),\n",
    "                           param_grid, cv=StratifiedKFold(5, shuffle = True, random_state = 1))\n",
    "\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "print_grid_search(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building SVC using best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 1.0000 \n",
      "testing score : 0.5400 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      1.00      0.70        81\n",
      "          2       0.00      0.00      0.00        15\n",
      "          3       0.00      0.00      0.00         5\n",
      "          4       0.00      0.00      0.00         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         3\n",
      "         10       0.00      0.00      0.00        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[81  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [17  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "AUC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=10, gamma=0.0001, kernel='rbf', random_state=1).fit(X_train_pca, y_train)\n",
    "\n",
    "print_model_scores(model = svc, X_test_scaled=X_test_pca, X_train_scaled=X_train_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search on Decision Tree to find best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 3}\n",
      "Best cross-validation score: 0.56\n",
      "Best estimator:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': np.arange(3, 10)}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=1),\n",
    "                           param_grid, cv=StratifiedKFold(5, shuffle = True, random_state = 1))\n",
    "\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "print_grid_search(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Decision tree using the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 0.6623 \n",
      "testing score : 0.5667 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.93      0.72        81\n",
      "          2       0.50      0.27      0.35        15\n",
      "          3       0.00      0.00      0.00         5\n",
      "          4       0.00      0.00      0.00         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.75      1.00      0.86         3\n",
      "         10       0.27      0.18      0.21        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.41      0.57      0.47       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[75  2  0  0  0  0  0  0  0  4  0  0  0]\n",
      " [ 9  4  0  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 5  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  1  0  0  0  0  0  0  1  1  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0]\n",
      " [14  0  0  0  0  0  0  0  0  3  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "AUC: 0.5584\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 3, random_state=1).fit(X_train_pca, y_train)\n",
    "\n",
    "print_model_scores(model = dt, X_test_scaled=X_test_pca, X_train_scaled = X_train_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Decision Tree using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 0.6623 \n",
      "testing score : 0.5533 \n",
      "Testing report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.94      0.71        81\n",
      "          2       0.40      0.27      0.32        15\n",
      "          3       0.00      0.00      0.00         5\n",
      "          4       0.00      0.00      0.00         5\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.33      0.50         3\n",
      "         10       0.33      0.12      0.17        17\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.41      0.55      0.45       150\n",
      "\n",
      "Confusion matrix: \n",
      "[[76  3  0  0  0  0  0  0  0  2  0  0  0]\n",
      " [10  4  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 5  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  1  1  0  0  0]\n",
      " [13  2  0  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "AUC: 0.5291\n"
     ]
    }
   ],
   "source": [
    "dt = BaggingClassifier(DecisionTreeClassifier(max_depth = 3, random_state=1)).fit(X_train_pca, y_train)\n",
    "\n",
    "print_model_scores(model = dt, X_test_scaled=X_test_pca, X_train_scaled = X_train_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search on GradientBoost to Find Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 3}\n",
      "Best cross-validation score: 0.57\n",
      "Best estimator:\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "             'max_depth':[3, 5, 9]}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(random_state = 1),\n",
    "                           param_grid, cv=StratifiedKFold(5, shuffle = True, random_state = 1))\n",
    "\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "print_grid_search(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Gradient Boosting using AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_clf = AdaBoostClassifier(GradientBoostingClassifier(learning_rate = 0.1,max_depth = 5,random_state = 1)).fit(X_train_pca, y_train)\n",
    "\n",
    "print_model_scores(model = dt, X_test_scaled = X_test_pca, X_train_scaled = X_train_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary <br>\n",
    "**Heart rate** undoubtedly won in all the models being the most important variable <br>\n",
    "**Few other important** variables are related to the R' wave, amplitudes in few channels (DII, V6) seeming the most important, age, weight and QRSA ratio.<br>\n",
    "In modeling, AUC was used to determine the model efficiency because there is a class imbalance issue here and accuracy would not be a good measure to calculate.<br>\n",
    "As we can see after pca any model did not perform better than before even though the variance was being captured.<br>\n",
    "**Dimensionality reduction did not help**<br>\n",
    "Support Vector Classifier with a linear kernel (C =1) or RBF kernel work well with AUC 71% but, bagging or boosting did not help there.<br>\n",
    "**Bagging and Boosting did not help**<br>\n",
    "Decision tree worked well but bagging boosted it's performace with AUC 71%<br>\n",
    "**Bagging and Boosting helped**<br>\n",
    "Random Forests did just fine with AUC 68%<br>\n",
    "Gradient boosting worked well with bagging and boosting giving AUC approximately 70%<br>\n",
    "**Bagging and Boosting helped**<br>\n",
    "All the other models did not work well<br>\n",
    "##### Finally, bagging and boosting may not work always, dimensionality reduction may not help always\n",
    "We decide to go with the Decision tree model using bagging or SVC classifier using a linear kernel if we had to drill down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
